{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "431ec010-bb64-4385-ae67-21dd6727a0cc",
   "metadata": {},
   "source": [
    "# Data Cleaning with Pandas and Jupyter Notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "599d94d9-381f-44db-9c1a-261f3ec48082",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path \n",
    "\n",
    "import sys\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "\n",
    "from scripts.normalize_data import (\n",
    "    normalize_columns, \n",
    "    normalize_expedition_section_cols,\n",
    "    remove_bracket_text,\n",
    "    remove_whitespace,\n",
    "    print_df\n",
    ")\n",
    "\n",
    "# from scripts.my_normalize_data import (\n",
    "#     normalize_columns, \n",
    "#     normalize_expedition_section_cols,\n",
    "#     remove_bracket_text,\n",
    "#     remove_whitespace,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6e052fab-68ce-4720-a524-d22903d7d801",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = list(Path('..', 'processed_data', 'clean_data').rglob('*.csv'))\n",
    "\n",
    "normalized_nontaxa_path = Path('..', 'processed_data', 'normalized_nontaxa_list.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6a3be3e0-b7c1-4074-b632-91f55e2a651e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c406300-17bc-4dcd-a8a2-a19c9102dbfc",
   "metadata": {},
   "source": [
    "## Basic file cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c489129-d83d-4369-a618-0065e0ce9840",
   "metadata": {},
   "source": [
    "Use pandas built in functions to do these steps\n",
    "\n",
    "- delete dataframe column if all values are NA \n",
    "\n",
    "  dropna(axis='columns', how='all', inplace=True)  \n",
    "\n",
    "- delete dataframe row if all values are NA \n",
    "\n",
    "  dropna(axis='index', how='all', inplace=True) \n",
    "\n",
    "- remove duplicate rows in dataframe \n",
    "\n",
    "  drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b73d7d5a-5e0e-4e4a-91ee-14567087f93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in paths:\n",
    "    df = pd.read_csv(path, dtype=str)\n",
    "    \n",
    "    # code to change file   \n",
    "    \n",
    "    df.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad25d0a-71c0-4ad9-a2f5-8c732a3602c6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## remove leading and trailing white spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d934a1-166a-4962-937e-68ecb5143495",
   "metadata": {},
   "source": [
    "created  `remove_whitespace` to remove all leading and trailing white spaces from a dataframe. \n",
    "\n",
    "Since we wanted to remove white spaces from the headers, we used `read_csv(header=None)` and `to_csv(header=False)` so that pandas treat the first row like any other row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ae3a6fc7-3b62-48d0-b59a-24336497151f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in paths:\n",
    "    df = pd.read_csv(path, dtype=str, header=None)\n",
    "    \n",
    "    remove_whitespace(df)\n",
    "    \n",
    "    df.to_csv(path, index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ae74e5-aa85-42f0-b12d-7c74a5d43926",
   "metadata": {},
   "source": [
    "## Normalizing columns names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffe563b-d86f-4a68-baeb-ccd695f11de5",
   "metadata": {},
   "source": [
    "### get all unique column names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c922f338-af67-4f2a-8600-bf15488903a0",
   "metadata": {},
   "source": [
    "Use `pandas.DataFrame.columns()` and python `set` to get all the unique columns for all the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5dddc5d-8f34-4f98-8793-d46664159fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_columns = set()\n",
    "\n",
    "for path in paths:\n",
    "    df = pd.read_csv(path, dtype=str, nrows=0)\n",
    "    \n",
    "    # code to get all column names  \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7419cd3-8eee-4835-aefd-d581164f0f6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c7a607-e2c1-47b7-9674-031bd627a2d9",
   "metadata": {},
   "source": [
    "Manually separate taxa names from other headers so that we could do some more processing on the taxa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0873975-b54e-42fb-a979-05fef12e24fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxa_columns = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74b94b27-01e3-4736-950e-f49d4d5c354b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(taxa_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1e6186-4d34-410f-9d29-5f3191bcdca1",
   "metadata": {},
   "source": [
    "Given `all_columns` and `taxa_columns`, find the `nontaxa_columns`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7978f7de-7d9c-49ba-8a19-f8331a311f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to get nontaxa_columns\n",
    "nontaxa_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2cdb4c23-bdd6-4975-83ce-69e965be77a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "472"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nontaxa_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff269b8-9656-45d5-8619-0108a24733b5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### create taxa and non-taxa file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8bff98-4362-4b90-a99c-81473ee383ca",
   "metadata": {},
   "source": [
    "Save the taxa and nontaxa headers to csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "439ee29c-65d1-4e3d-8a52-4d0ebc992dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('..', 'processed_data', 'drafts', 'taxa_list.csv')\n",
    "\n",
    "# create taxa dataframe an save it as a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "636ba39d-f50d-4560-a334-7868f9d68d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('..', 'processed_data', 'drafts', 'nontaxa_list.csv')\n",
    "\n",
    "# create nontaxa dataframe an save it as a csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a36ae29-c7a3-4b09-b31f-f2b5ede98e1a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### normalize headers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714444e3-8b4f-49d9-b9c3-3285e31acbad",
   "metadata": {},
   "source": [
    "create `normalize_columns` to update the column names for a data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b265f1ac-9298-453d-9bd4-6715a02b1667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>field</th>\n",
       "      <th>normalized_field</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A/W</td>\n",
       "      <td>A/W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Additional zone name</td>\n",
       "      <td>Additional zone name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Additional zone name (short)</td>\n",
       "      <td>Additional zone name (short)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bottom Depth [m]</td>\n",
       "      <td>Bottom Depth [m]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bottom Depth[m] [m]</td>\n",
       "      <td>Bottom Depth [m]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          field              normalized_field\n",
       "0                           A/W                           A/W\n",
       "1          Additional zone name          Additional zone name\n",
       "2  Additional zone name (short)  Additional zone name (short)\n",
       "3              Bottom Depth [m]              Bottom Depth [m]\n",
       "4           Bottom Depth[m] [m]              Bottom Depth [m]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nontaxa_df = pd.read_csv(normalized_nontaxa_path, dtype=str)\n",
    "print_df(nontaxa_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71655b85-d6f6-46f0-b3e0-0181ca46173f",
   "metadata": {},
   "source": [
    "create a dictionary that lists the original field name and normalized field name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "28e90c5b-82ab-486c-b14d-04a620c0ef3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nontaxa_mapping = nontaxa_df.set_index('field').to_dict()['normalized_field']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf368eb9-56d1-44ac-a7e8-dc4eba6edd1a",
   "metadata": {},
   "source": [
    "normalize columns for all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d99e78a3-70ea-46c5-8919-a082dd13a4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in paths:\n",
    "    df = pd.read_csv(path, dtype=str)    \n",
    "    \n",
    "    normalize_columns(df, nontaxa_mapping)\n",
    "    \n",
    "    df.to_csv(path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2301d154-bcf7-498e-a53d-22d4f3c154d4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Clean up row values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17b48f6-59c7-46b9-be99-1f8d013a666c",
   "metadata": {},
   "source": [
    "create `remove_bracket_text` to remove the [text] values at the end of some taxa columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "15ee2cbc-1606-46c4-9aab-df0fed3d3e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in paths:\n",
    "    df = pd.read_csv(path, dtype=str)\n",
    "    \n",
    "    df = remove_bracket_text(df)\n",
    "    \n",
    "    df.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8d5fb7-0647-4e69-8c47-eeed6c901306",
   "metadata": {},
   "source": [
    "## Turn one column into multiple columns "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d13bffb-fc8e-475c-a8c2-abceb1f2d313",
   "metadata": {},
   "source": [
    "For some files, `Sample` column was given, but `Exp, Site, Hole, Core, Type, Section, A/W` columns where not given. `normalize_expedition_section_cols` converts `Sample` into separate `Exp, Site, Hole, Core, Type, Section, A/W` columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6c772dac-baaa-4341-9659-507cb0381522",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in paths:\n",
    "    df = pd.read_csv(path, dtype=str)   \n",
    "    \n",
    "    df = normalize_expedition_section_cols(df)\n",
    "    \n",
    "    df.to_csv(path, index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab453e2b-462f-4c8f-ad5f-5a50f9e89246",
   "metadata": {},
   "source": [
    "## check if mandatory columns exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9c6cbced-57f8-4481-902d-bfc14e22cff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "required_columns = {\n",
    " 'A/W',\n",
    " 'Bottom [cm]',\n",
    " 'Bottom Depth [m]',\n",
    " 'Core',\n",
    " 'Exp',\n",
    " 'Hole',\n",
    " 'Sample',\n",
    " 'Section',\n",
    " 'Site',\n",
    " 'Top [cm]',\n",
    " 'Top Depth [m]',\n",
    " 'Type'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b471b3f1-2b27-4e68-a58b-27c27b1e42c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../processed_data/clean_data/Micropal_CSV_1/318_U1355A_Planktic_Forams.csv\n",
      "{'Sample'}\n",
      "../processed_data/clean_data/Micropal_CSV_1/318_U1359A_Planktic_Forams.csv\n",
      "{'Sample'}\n",
      "../processed_data/clean_data/Micropal_CSV_1/318_U1359D_Planktic_Forams.csv\n",
      "{'Sample'}\n",
      "../processed_data/clean_data/Micropal_CSV_3/323_U1343B_planktic_forams.csv\n",
      "{'Sample'}\n",
      "../processed_data/clean_data/Micropal_CSV_3/330_planktic_forams_U1374A.csv\n",
      "{'Sample', 'Top Depth [m]', 'Top [cm]', 'Bottom Depth [m]', 'Bottom [cm]'}\n"
     ]
    }
   ],
   "source": [
    "for path in paths:\n",
    "    df = pd.read_csv(path, dtype=str)    \n",
    "    cols = set(df.columns)\n",
    "    diff = required_columns - cols\n",
    "    \n",
    "    if(len(diff) > 0):\n",
    "        print(path)\n",
    "        print(required_columns - cols)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feae0a31-be50-4a16-8a73-41ddab608cc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
